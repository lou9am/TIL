# CH02 데이터
컴퓨터는 0과 1로 모든 정보를 표현하고, 0과 1로 표현된 정보만을 이해할 수 있다. 컴퓨터가 이해하는 가장 작은 정보 단위를 '비트'라고 한다.  


## 비트와 바이트
- 1byte는 8bit
- 1kB는 1000byte
- 1MB는 1000kB
- 1GM는 1000MB

### 주의!
1024개씩 묶어 표현하는 단위는 KiB, MiB, GiB, TiB이다.

### 워드(Word)
워드란 `CPU가 한 번에 처리할 수 있는 데이터의 크기`를 의미한다. 만약 CPU가 한 번에 16비트를 처리할 수 있다면 1워드는 16비트가 된다.

이렇게 정의된 워드의 절반 크기를 하프 워드, 1배 크기를 풀 워드, 2배 크기를 더블 워드라고 부른다. 워드 크기는 CPU마다 다르지만 대부분 32비트 또는 64비트이다. 

## 이진법
- 이진수는 끝에 아래첨자 (2)를 붙이거나 앞에 0b를 붙여 구분한다.

### 이진수의 음수 표현
- 이진수의 음수는 `2의 보수법`을 이용한다. 모든 이진수의 0과 1을 뒤집은 수를 `1의 보수`라고 하며, 거기에 1을 더한 값이 `2의 보수`이다.
- 컴퓨터 내부에서 어떤 수를 다룰 때는 이 수가 양수인지 음수인지를 구분하기 위해 `플래그(flag)`를 사용한다.
- 2의 보수법은 n비트로 -2^n과 2^n을 동시에 표현할 수 없다는 한계점이 있다.

## 십육진법
- 이진수로 나타내면 숫자가 너무 길어지기 때문에 십육진수를 사용한다. 심육진수를 사용하는 이유는 이진수와 십육진수 사이의 변환이 쉽기 때문이다.
- 십육진수는 앞에 0x를 붙여 구분한다.
- 하드웨어와 밀접하게 맞닿아 있는 개발 분야에서는 코드에 십육진수를 직접 쓰는 경우가 종종 있다.

<br>

---

<br>

## 문자 집합과 인코딩
컴퓨터가 인식하고 표현할 수 있는 문자의 모음을 `문자 집합`이라고 한다. 이 문자들을 컴퓨터가 이해할 수 있는 0과 1로 표현하는 과정을 `인코딩`, 반대로 0과 1로 표현된 문자 코드를 사람이 읽을 수 있는 문자로 변환하는 과정을 `디코딩`이라고 한다.

## 아스키 코드
- 아스키 코드는 초창기 문자 집합 중 하나로, 영어 알파벳과 아라비아 숫자, 그리고 일부 특수 문자를 `7비트`로 표현한다. 7비트로 표현하기 때문에 총 `128개`의 문자를 표현할 수 있다.
- 실제로는 하나의 아스키 문자를 나타내기 위해 8비트를 사용하지만, 그중 `1비트는 패리티 피트`로 오류 검출을 위해 사용되므로 실질적으로 문자 표현에 사용되는 비트는 7비트이다.

## EUC-KR
- 아스키 코드는 한글을 표현할 수 없다. 따라서 한글 인코딩을 위해 등장한 방식이 EUC-KR이다.
- 한글 인코딩 방식에는 완성형과 조합형이 존재하는데 EUC-KR은 `완성형 인코딩 방식`이다.
- 초성, 중성, 종성이 모두 결합된 한글 단어에 `2바이트` 크기의 코드를 부여한다.

## 유니코드와 UTF-8
- 유니코드는 여러 나라의 문자를 광범위하게 표현할 수 있는 통일된 문자 집합이다.
- 유니코드는 글자에 부여된 값 자체를 인코딩된 값으로 삼지 않고 이 값을 다양한 방법으로 인코딩한다. 유니코드 인코딩 방식에는 `UTF-8`, `UTF-16`, `UTF-32` 등이 있다. (UTF : Unicode Transformation Format)
- UTF-8은 통상 `1바이트부터 4바이트`까지의 인코딩 결과를 만들어 낸다.

#### 출처  
[1] 혼자 공부하는 컴퓨터구조 + 운영체제 - 강민철 지음
