

## Map Reduce
최근 컴퓨팅 환경에서는 저가형 서버들을 클러스팅하여 대규모 고성능 컴퓨팅 플랫폼을 구축하는 일에 노력을 쏟고 있다. 구글의 MapReduce는 대용량 데이터를 분산 처리하기 위한 프로그래밍 모델로, 대용량 데이터를 다루는 환경에 많은 영향을 주고 있다.

- 구글에서 `분산 병렬 컴퓨팅`을 이용하여 대용량 데이터를 처리하기 위한 목적으로 제작한 소프트웨어 프레임워크.
- `분할정복 방식`으로 `대용량 데이터를 병렬로 처리`할 수 있다.
- MapReduce 작업은 특별한 옵션을 주지 않으면 `Map Task 하나가 1개의 블록(64MB)을 대상으로 연산을 수행`한다.


### 1. 구글 MapReduce
Map과 Reduce 2개의 단계로 나뉜다.

- Map에서는 key와 value의 쌍들을 입력받는다.
- 하나의 key, value 쌍들은 사용자가 정의한 map 함수를 거치면서 다수의 새로운 key, value 쌍들로 변환된어 로컬 파일시스템에 임시 저장된다.
- 저장된 임시 파일들은 프레임워크에 의해 Reduce에게 전송된다. 이때, 자동으로 `shuffling`과 `group by` 정렬의 과정을 거친다.
- 사용자 관점에서는 장애 복구와 같은 세세한 이슈들을 신경 쓸 필요 없이 Map과 Reduce 두 함수만 작성함으로 대규모 병렬 연산 작업을 수행할 수 있다.
- MapReduce 모델은 분산 Grep이나 빈도 수 계산등의 작업에 적합하며, 정렬과 같은 작업은 입력 데이터의 사이즈가 줄지 않고 그대로 Reduce로 전해지므로 오버헤드에 따라 수행 성능이 저하된다.

<br>

### 2. Hadoop MapReduce
하둡은 `데몬` 관점에서 4개의 구성 요소를 가지고 있다.

__* 데몬__ : 서버의 메인메모리 상에서 백그라운드로 수행되는 프로그램

|구분|설명|
|---|---|
|네임노드|하둡을 이루는 가장 기본적이고 필수적인 데몬, 마스터 역할을 수행|
|데이터노드|분산 파일 시스템의 데몬, 파일의 실질적인 데이터 입출력에 대한 처리를 수행|
|잡트래커|MapReduce 시스템에서 job이라는 작업을 관리하는 마스터|
|태스크트래커|작업을 수행하는 워커 데몬, 슬레이브에 해당|

#### Hadoop MapReduce의 실행절차
1. __Split__ : HDFS의 대용량 입력 파일을 분리하여 __파일스플릿을 생성__하고, __파일스플릿 하나당 맵 태스크 하나씩을 생성__한다.
2. __Map__ : 각 split에 대해서 레코드 단위로 map함수를 적용하여 key-value 쌍을 생성한다.
3. __Combine__ : 리듀스 단계로 데이터를 보내기 전에 중간 결과값들을 처리하여 데이터의 크기를 줄여준다.
4. __Partition__ : key를 기준으로 데이터를 디스크에 분할 저장, 분할된 파일들은 각각 다른 리듀스 태스크에 저장된다.
5. __Shuffle__ : 여러 맵퍼들의 결과 파일을 각 리듀서에 할당, 할당된 파일을 로컬 파일 시스템으로 복사한다.
6. __Sort__ : 병합 정렬 방식을 이용하여 맵퍼의 결과를 정렬한다.
7. __Reduce__ : 정렬 단계에서 생성된 파일에 대해 리듀스 함수를 적용한다.

#### 하둡의 성능
- MapReduce에서 sort는 어떠한 작업을 실행하더라도 Map에서 Reduce로 넘어가는 과정에서 항상 발생하는 내부적인 프로세스이다.
- sort 작업은 데이터가 커질수록 처리 시간이 선형적으로 증가한다.
